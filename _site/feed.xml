<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-10-12T22:06:05-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Olabode Anise</title><subtitle>Olabode Anise | My musings on security, data, and probably sports</subtitle><author><name>Olabode Anise</name></author><entry><title type="html">Your Secrets Are Safe: How Browsers’ Explanations Impact Misconceptions About Private Browsing Mode</title><link href="http://localhost:4000/paper%20summary/your-secrets-are-safe/" rel="alternate" type="text/html" title="Your Secrets Are Safe: How Browsers’ Explanations Impact Misconceptions About Private Browsing Mode" /><published>2020-02-29T00:00:00-08:00</published><updated>2020-02-29T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/your%20secrets-are-safe</id><content type="html" xml:base="http://localhost:4000/paper%20summary/your-secrets-are-safe/">&lt;p&gt;&lt;a href=&quot;https://www.blaseur.com/papers/www18privatebrowsing.pdf&quot;&gt;Your Secrets Are Safe: How Browsers’ Explanations Impact Misconceptions About Private Browsing Mode&lt;/a&gt; Yuxi Wu et al., World Wide Web Conference 2018&lt;/p&gt;

&lt;p&gt;With this paper, I’m taking it back to 2018. I found this paper by Yuxi Wu et al. particularly interesting because it centers around a feature of browsers that a good amount of people use and/or is sometimes recommended as a way of staying safe on the internet: “private browsing.” In their work, they focus specifically on the disclosures users see when they open a new  window in a browser’s &lt;em&gt;private mode&lt;/em&gt; and some of the misconceptions users have about the privacy guarantees when using these modes.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/assets/images/your-secrets-are-safe/incognito.png&quot; alt=&quot;t&quot; /&gt;
  
    &lt;figcaption&gt;
      Google Chrome’s Incognito Mode Disclosure

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;setting-the-stage&quot;&gt;Setting the Stage&lt;/h2&gt;
&lt;p&gt;If you’re not familiar with private mode, it’s a feature that each of the major browsers has that is geared towards protecting users against &lt;em&gt;local privacy threats&lt;/em&gt; such as someone seeing your browser history on a shared device. Each browser calls their version of private mode something different but they are more or less the same. When using private mode, a user’s browser history is not stored after a session is closed, cookies are cleared after the session is closed, and temporary files are deleted. To reiterate, private mode does not protect against remote threats. The two exceptions to certain degrees are Opera’s Free VPN that has to be enabled by the user and Firefox’s &lt;a href=&quot;https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop&quot;&gt;Enhanced Tracking Protection&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;meet-the-browser-onyx&quot;&gt;Meet the browser: Onyx&lt;/h2&gt;
&lt;p&gt;To understand the misconceptions users have surrounding private browsing Wu et al. designed an experiment where they had users imagine a new browser called Onyx. With this “new browser”, they presented a simulated browser window where they used the disclosure for each of the following browsers: Brave, Chrome, Edge, Firefox, Opera, Safari and a control that vaguely described some privacy guarantees. They also tested the mobile versions of each of the majors browsers except Edge. Their experiment followed a between subject’s design where each study participant only saw one of the 13 disclosure. If you’re doing some math and you’re like that doesn’t add up to 13, you’d be right. Wu al. tested two versions of the Chrome browser (59 and 60) because at the time Google had recently changed their disclosure.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/assets/images/your-secrets-are-safe/table1.png&quot; alt=&quot;&quot; /&gt;
  
    &lt;figcaption&gt;
      Portion of Table 1

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;After showing each participant was shown the disclosure for their condition, they were presented with twenty browsing scenarios. 16 of these scenarios were designed to measure the differences participants perceived between private mode and standard mode. In the other four scenarios, participants were asked multiple choice questions in which they were asked to make relative comparisons between the two modes.  An example question is “How will the speed at which webpages load compare in standard vs private browsing modes?” After seeing each scenario, participants were asked a yes or no question and then asked how confident they were in their answers (Very Confident, Confident, Somewhat confident, Not at all confident). Finally, they were asked why they chose a particular answer.&lt;/p&gt;

&lt;p&gt;At the very end of each session, Wu et al. collected demographic information, information on their browser usage and usage of private mode.&lt;/p&gt;

&lt;p&gt;Specifically, they set out to answer the following research questions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How do each of the six desktop disclosures compare to the control?&lt;/li&gt;
  &lt;li&gt;How do mobile versions of disclosures compare to the disclosure in the same browser’s desktop version&lt;/li&gt;
  &lt;li&gt;How does the recently redesigned Chrome disclosure compare to the previous disclosure.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;results&quot;&gt;Results&lt;/h2&gt;
&lt;p&gt;In total, they recruited 460 participants from Amazon Mechanical Turk and found that approximately ~97% of participants used Google Chrome for desktop browsing and that 80% of participants used private browsing at least some of the time. They found that the top six reasons users used private browsing were 1) hide browsing, especially visits to adult websites 2) prevent targeted ads and search suggestions 3) achieve “safer” browsing 4) prevent browsers from saving login-related information 5) avoid cookies 6) accommodate intentional or unintentional use by others.&lt;/p&gt;

&lt;p&gt;To understand the impact each of the disclosures had on a participant’s understanding of private mode, Wu et al. created a correctness and confidence score. The correctness score was just the total number of scenarios that the participant answered correctly excluding the six scenarios where the correct answer was browser dependent. The confidence score was the sum of the confidence ratings for the same 14 scenarios. Using those two scores they created regression models using demographic and study-related characteristics. In the end, they found that most of the disclosures had no significant impact on a participant’s understanding of what private mode does or doesn’t do. Specifically, only the participants who were shown one of the two versions of Chrome for desktop disclosure answered more correctly than the control group. They also found that the mobile disclosures were less successful than the control.&lt;/p&gt;

&lt;h3 id=&quot;non-misconceptions&quot;&gt;(Non-)Misconceptions&lt;/h3&gt;
&lt;p&gt;Wu et al. denoted scenarios where over 20% of participants across disclosures answered the question about private mode incorrectly as misconceptions. While they found there were a lot of misconceptions there were a good amount of scenarios that almost all participants got correct. Some examples are 97% of participants correctly realized that files downloaded in private mode would remain on the computer after the session has ended and 90% of participants knew that photos viewed in the browser during private mode would not be cached for quicker loading during future sessions. On the flip side, participants both over and underestimated the protection private mode offers. The most notable overestimate was that 22%, 37%, and 23% of participants respectively believed that ISPs, employers and the government could not track them when they used private mode. In terms of underestimates, 30% of participants incorrectly thought that their searches could be associated across sessions.&lt;/p&gt;

&lt;h2 id=&quot;bringing-it-to-2020&quot;&gt;Bringing it to 2020.&lt;/h2&gt;
&lt;p&gt;Since this research was conducted in 2017, I decided to take a look at the disclosures for Brave, Safari, Chrome and Firefox to see if they had made any significant changes and if so what. What I found is that each of the four browsers had changed their disclosures for both mobile and desktop versions except for Safari. In the case of Chrome, Google has opted to use the same disclosure across both the mobile and desktop version which I think is a positive change.  By using the same disclosure for both versions, it’s possible to rule out that misconceptions were derived simply from seeing a different version on a different platform.  Overall, the mobile versions of each of the browsers tested in 2017 had far less text describing what private mode did/did not do. While that still proves to be the case, Brave-Mobile (and Chrome-Mobile by default) has made massive improvements in terms of providing additional information on the privacy guarantees when using private mode on their mobile browser.&lt;/p&gt;

&lt;figure class=&quot;&quot;&gt;
  &lt;img src=&quot;/assets/images/your-secrets-are-safe/firefox.png&quot; alt=&quot;&quot; /&gt;
  
    &lt;figcaption&gt;
      Disclosure for Firefox v73.0.1

    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;I’d be remiss if I didn’t mention the changes Firefox has made. As you can see in the figure above, Firefox provides users a link to a page that dispels some of the myths about private browsing. I think just having a link is a big step in the right direction and gives users an easily accessible resource to get more information on what guarantees they have when using private mode even if it takes a bit more work.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;It seems like most browsers are making efforts to improve the disclosures users see when entering private mode. Nevertheless, there are still some areas that they could improve on. It would be interesting to see if the results by Wu et al. would be the same given the current set of disclosures.&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">Your Secrets Are Safe: How Browsers’ Explanations Impact Misconceptions About Private Browsing Mode Yuxi Wu et al., World Wide Web Conference 2018</summary></entry><entry><title type="html">\“If HTTPS Were Secure, I Wouldn’t Need 2FA\” - End User and Administrator Mental Models of HTTPS</title><link href="http://localhost:4000/paper%20summary/if-https-were-secure/" rel="alternate" type="text/html" title="\“If HTTPS Were Secure, I Wouldn’t Need 2FA\” - End User and Administrator Mental Models of HTTPS" /><published>2020-02-22T00:00:00-08:00</published><updated>2020-02-22T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/if-https-were-secure</id><content type="html" xml:base="http://localhost:4000/paper%20summary/if-https-were-secure/">&lt;p&gt;&lt;a href=&quot;https://publications.cispa.saarland/2788/&quot;&gt;“If HTTPS Were Secure, I Wouldn’t Need 2FA” - End User and Administrator Mental Models of HTTPS&lt;/a&gt; Katharina Krombholz et al., IEEE Symposium on Security and Privacy 2019&lt;/p&gt;

&lt;p&gt;In the short time that I’ve recommitted to reading Usable Security papers, I found this paper my Krombholz et al., to be the most fascinating. In their paper, they try to understand the root causes of common misconception of HTTPS by formalizing the mental models of end-users and administrators.&lt;/p&gt;

&lt;h2 id=&quot;primer-on-mental-models&quot;&gt;Primer on Mental Models&lt;/h2&gt;
&lt;p&gt;Mental models are an important concept in Psychology, HCI, Behavioral Economics but it may seem a bit complex if you haven’t been exposed to it; so let’s take a few minutes to talk about what they are. Using Wikipedia’s definition, “A mental model is an explanation of someone’s thought process about how something works in the real world. [1]” The hope is that someone’s mental model closely matches reality but that’s not always the case. Moreover, many Usable Security papers have proved as much. This misalignment can have serious consequences as it relates to security since these mental models will have influence on the decisions a user makes in certain situations.&lt;/p&gt;

&lt;h2 id=&quot;why-you-asking-all-them-questions&quot;&gt;Why you asking all them questions?&lt;/h2&gt;
&lt;p&gt;In their work, Krombholz et al. tried to answer the following questions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;What are people’s expectations and perceptions of encryption and visiting sites via HTTPS&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How well do users understand the associated threat models&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What are the differences between end users’ and administrators’ mental models of HTTPS&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;getting-some-answers&quot;&gt;Getting some answers&lt;/h2&gt;
&lt;p&gt;Krombholz et. al, designed their study to try to understand the tacit knowledge both administrators and end users have about HTTPS. They did so by having participants perform three drawing tasks based on three different scenarios:&lt;/p&gt;

&lt;p&gt;1) a general scenario of sending an encrypted message to a communication partner&lt;/p&gt;

&lt;p&gt;2) online shopping via HTTPS&lt;/p&gt;

&lt;p&gt;3) online banking&lt;/p&gt;

&lt;p&gt;The results they reported in their paper were based on 30 interviews from 12 administrators and 18 end-users. A limitation that authors pointed out was that their study population was not very diverse. The end-user participants skewed more female while the sample of participants was completely male.&lt;/p&gt;

&lt;h2 id=&quot;expectations&quot;&gt;Expectations&lt;/h2&gt;

&lt;p&gt;One of the things that I appreciated about this paper is that they explicitly laid out their expectations and acknowledged how they could influence their analysis of the data.&lt;/p&gt;

&lt;p&gt;Krombholz et al. argue that the mental models of both end users and admins are built on the protocols and UX in which they interact. So, they thought those components would be central to participants’ mental models. Specifically for end users, they thought they would not have deep knowledge about encryption concepts but that their mental models would security indicators (e.g., the padlock icon). For administrators, they expected more in-depth knowledge that would include things like certificates, CAs, symmetric and asymmetric encryption, etc.&lt;/p&gt;

&lt;h2 id=&quot;mental-models&quot;&gt;Mental Models&lt;/h2&gt;

&lt;p&gt;Through their coding of participant models, Krombholz et al., found four different types of mental models that represented different levels of understanding of HTTPS and message encryption.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/if-https-were-secure/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The figure above is the model of message of message encryption that correctly abstracts the underlying technology. This model has concepts such as encryption and decryption performed at the communication endpoints, shows that the data in transit is protected from attackers, and at least acknowledges the existence of different types of keys. In the paper, the authors point out that while the model is conceptually correct that it is still fairly sparse when it comes to the purpose of these different entities.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/if-https-were-secure/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The second model was what the authors referred to as the anti-model of message encryption. This model is shown in the figure above and includes a centralized authority that performs actions such as encryption and authentication, shows that data isn’t protected from attackers and doesn’t include keys. This anti-model was only common among end-users in their study population.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/if-https-were-secure/figure4.png&quot; alt=&quot;figure 4&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The third model similar to the first model shown for message encryption had correct mental representations of the concepts and entities in HTTPS. This model had the following properties: data in transit was encrypted and protected from attackers, had the existence of a CA, the browser was perceived as a relevant entity. The authors found that the admins’ mental models contained more entities such as certificate checks, TLS handshakes, etc.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/if-https-were-secure/figure5.png&quot; alt=&quot;figure 5&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The last model was the anti-model of HTTPS. This model contained things such as omnipotent attackers like intelligence agencies, the concept that smartphones were generally insecure, and 2FA as an additional layer of encryption. Unlike the message encryption anti-model, the authors found that 2 admins models also contained elements of this anti-model.&lt;/p&gt;

&lt;h2 id=&quot;themes&quot;&gt;Themes&lt;/h2&gt;
&lt;p&gt;In their paper, Krombholz et al., lay out some of themes that emerged from the drawing tasks and think-aloud protocol. There are &lt;em&gt;a lot&lt;/em&gt; of them but I want to call out a few.&lt;/p&gt;

&lt;p&gt;One of the more interesting ones was that they found that half of the participants in the end-user sample had never noticed the security indicators before. This ran counter to the authors’ expectations. Moreover, it shows that despite the extensive work that has been put into improving HTTPS security indicators end users still don’t properly recognize them. Also, they found that some end users and admins just didn’t trust the security indicators or HTTPS as a protocol.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The lock symbol does not mean anything, it is pure marketing. (A06)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Krombholz et al. also found that there were misconceptions surrounding the differences between authentication and encryption for both end users and admins. This misconception is where the title of the paper comes from.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;HTTPS is a bad protocol. If HTTPS were secure, I wouldn’t need 2FA (U11)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The last theme that I want to call out from the paper relates to the differences between admins and end users. Krombholz et al., found that the mental models of end users were more conceptual while the mental models of admins were more protocol based. Basically, most of the admins showed familiarity with specific things related to the protocol. However, when asked to explain the underlying concepts of HTTPS, most admins were unable to.&lt;/p&gt;

&lt;p&gt;With their findings on the difference in mental models among admins and end users, Krombholz et al. argue that end users and even admins to a certain extent, shouldn’t be expected to have fully correct mental models of HTTPS.&lt;/p&gt;

&lt;h2 id=&quot;so-what&quot;&gt;So what?&lt;/h2&gt;
&lt;p&gt;You might be thinking to yourself, “Who cares if people have (in)correct or sparse mental models?” So there is actually a good deal to care about and Krombholz et al point that out in their paper. Participants who had incorrect mental models were more likely to underestimate the security benefits of HTTPS and thought omnipotent attackers could eavesdrop. This type of thinking can lead to users making incorrect security decisions. On the other end of the spectrum, they found that one end user thought that HTTPS could protect them from being phished. This type of assumption leads to a false sense of security when using HTTPS.&lt;/p&gt;

&lt;h2 id=&quot;making-things-better&quot;&gt;Making things better&lt;/h2&gt;
&lt;p&gt;Krombholz et al., provide a lot of suggestions on how to improve both end users’ and admins’ understanding of HTTPS. In the case of admins, they suggest that tools like Let’s Encrypt and Certbot provide tangible explanations of things like keys and certificates so improve admins understandings of the different protocol components. For end users, they suggest that protocols should offer state of the art encryption by default and that insecure protocols should be abandoned. They believe this would help establish a more user-friendly distinction between best-case security and vulnerable connections. They also call out the work by Google which doesn’t show any security indicators for sites using HTTPS but shows a red security indicator for those sites using HTTP.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;Krombholz and her collaborators show that there are a lot of misconceptions about HTTPS among both end users and admins and that these misconceptions lead to decisions that can put themselves and potentially others at risk.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] https://en.wikipedia.org/wiki/Mental_model&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">“If HTTPS Were Secure, I Wouldn’t Need 2FA” - End User and Administrator Mental Models of HTTPS Katharina Krombholz et al., IEEE Symposium on Security and Privacy 2019</summary></entry><entry><title type="html">Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media</title><link href="http://localhost:4000/paper%20summary/beyond-set-it-and-forget-it/" rel="alternate" type="text/html" title="Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media" /><published>2020-02-08T00:00:00-08:00</published><updated>2020-02-08T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/beyond-set-it-and-forget-it</id><content type="html" xml:base="http://localhost:4000/paper%20summary/beyond-set-it-and-forget-it/">&lt;p&gt;&lt;a href=&quot;https://www.cs.uic.edu/~elena/pubs/mondal-ccs19.pdf&quot;&gt;Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media&lt;/a&gt; Mainack Mondel et al., Conference on Computers and Communication Security 2019&lt;/p&gt;

&lt;p&gt;The last paper that I looked at from CCS is a bit different than the four previous papers that I’ve summarized that have focused on the usability of libraries, methods, and technologies. This work by Mandal and his collaborators centers around user privacy on Facebook. There is also a bit of machine learning, but I promise you there won’t be too much math. With that said, let’s dig in!&lt;/p&gt;

&lt;h2 id=&quot;privacy-on-facebook&quot;&gt;Privacy on Facebook&lt;/h2&gt;

&lt;p&gt;The main thread throughout the paper is that a user’s preference with whom to share data (in this case Facebook posts) may change over time. In the case of Facebook, the number of friends a user has now could be many times higher than when a particular post was first made. As a result, the privacy settings that were originally used on a post may not be appropriate given a user’s new connections.&lt;/p&gt;

&lt;p&gt;As a primer for those that don’t use Facebook, Facebook allows users to control who sees their posts through the Audience Selector. Mainack et al., do a great job in comparing it to traditional role-based access control where the roles are as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;public&lt;/strong&gt;: anyone can see it&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;friends+&lt;/strong&gt;: the user’s Friends plus the friends of some/all of those friends&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;friends&lt;/strong&gt;: the user’s Facebook friends&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;custom&lt;/strong&gt;: a user-specified subset of Facebook friends&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;only me&lt;/strong&gt;: only the user&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;goals&quot;&gt;#Goals&lt;/h2&gt;
&lt;p&gt;In the work by Mandal et al., they try to build an understanding of Facebook privacy attitudes and and practices and how those may change over time through a user study with the goal of translating those findings into a human-in the-loop privacy management system.&lt;/p&gt;

&lt;h2 id=&quot;user-study&quot;&gt;User Study&lt;/h2&gt;

&lt;p&gt;In addition to understanding the privacy practices and attitudes of Facebook users, they conducted the user study to get data to be used later to test a predictive model.&lt;/p&gt;

&lt;h3 id=&quot;recruitment-and-demographics&quot;&gt;Recruitment and Demographics&lt;/h3&gt;
&lt;p&gt;They recruited participants using Amazon MTurk who were at least 18 years of age and located in North America. In total, they had 101 participants. Over 2/3 of their participants identified as female. 46% of participants fell in the 25-34 age range which was consistent with the overall age distribution of Facebook users in 2018 [1]. 87% of participants identified as white. In terms of Facebook usage, approximately 90% of participants reported using Facebook daily. More info about their usage can be found in the table below.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/set-it-and-forget-it/table2.png&quot; alt=&quot;table 2&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;getting-data-and-labels&quot;&gt;Getting Data and Labels&lt;/h3&gt;
&lt;p&gt;In order to collect participant data, they had each participant download a browser extension. The extension collects an anonymized version of their full Facebook timeline as well as their Facebook activity log. This was accomplished by the browser extension sharing their session cookie with a server at University of Chicago which used Selenium to download the relevant parts of the participant’s timeline and activity log. In the paper, Mandal et al. provide more detail than I can put in this summary about how they try to collect the data in privacy preserving way. A diagram of the protocol that they used can be seen in the figure below.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/set-it-and-forget-it/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After they collected each participant’s data, they did a two-part survey. In Part 1, they randomly selected five posts from a participants timeline. Then they showed them the posts current privacy settings and if they had changed the posts settings or considered changing them. Last, they asked if the participant wanted to change those settings or keep them the same and why. In part two, they used those same posts but they showed six of the participant’s Facebook friends who could see the post. They also asked whether or not the participant wanted to continue sharing that post with that person or if they didn’t care. The six friends were picked from six categories of interaction where interaction was measured through things like number of words exchanges via posts and comments and the number of reactions the participant and their friend gave each other on posts. More information on those six categories can be found in the table below.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/set-it-and-forget-it/table2.png&quot; alt=&quot;table 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In addition to the post experiment, participants completed a survey which asked about their overall Facebook usage and their use of Facebook’s privacy features.&lt;/p&gt;

&lt;h3 id=&quot;findings-from-the-data&quot;&gt;Findings from the Data&lt;/h3&gt;
&lt;p&gt;In examining the longitudinal data, they found that friends (the default setting) was the most used privacy setting. The reason that this is important is that because the number of friends each participant had increased over time they were therefore sharing these older posts with more and more people. Another interesting but intuitive finding from the survey they administered was that a participant’s life changes impacted their privacy settings. The most common personal changes that were cited were relationship changes and childbirth.&lt;/p&gt;

&lt;p&gt;Shifting gears to the two post experiments, Mandal et al. found that the majority (~75%) of posts didn’t require any changes, but 63.5 participants wanted to change the privacy settings on at least one post. Interestingly enough, the changes that participants wanted to make were roughly split between increasing and decreasing the audience size.&lt;/p&gt;

&lt;p&gt;Mandal et al. also explored the correlation between participants’ privacy preferences and the interactions they had with a particular user. They found that participants were more likely to share posts with friends whom they had a high degree of recent interactions with than those who they had not recently interacted with. That makes a lot of sense; however, the inverse wasn’t true. Participants also wanted to “definitely keep sharing” posts with 35% of the friends who they hadn’t had any interaction with in the past year. When they examined the qualitative data that was collected, Mandal and his collaborators found that 35% fell into the categories of family member or close friend.&lt;/p&gt;

&lt;h2 id=&quot;lets-do-some-prediction&quot;&gt;Let’s Do Some prediction&lt;/h2&gt;
&lt;p&gt;As mentioned earlier, the ultimate goal was to help users have the right privacy settings for posts that were made in the past no matter how old they are. Because the amount of posts can be large the only reasonable course of action would be to use some type of automated system. Cue Machine Learning!&lt;/p&gt;

&lt;h3 id=&quot;problem-formulation&quot;&gt;Problem formulation&lt;/h3&gt;
&lt;p&gt;Mandal et al. formulated the problem as binary classification where the two classes were &lt;em&gt;limit sharing&lt;/em&gt; and &lt;em&gt;do not limit sharing&lt;/em&gt;. They also stress that they would want this to be a human-in-the loop system and not a “fully automatic post manager.”&lt;/p&gt;

&lt;h3 id=&quot;data-and-features&quot;&gt;Data and Features&lt;/h3&gt;
&lt;p&gt;The features that they used were composed of information gathered through the survey responses, user information, posts statistics, content, and audience. For post statistics, they used things like the number of likes and comments, whether or not another user was tagged, etc. They also used NLP methods to extract content-level features from the text of posts.&lt;/p&gt;

&lt;h3 id=&quot;evaluation&quot;&gt;Evaluation&lt;/h3&gt;
&lt;p&gt;Mandal et al. evaluated several models such as Decision Trees, Logistic Regression, and Support Vector Machines. The results of these models were tested against two baselines. The first was a random classifier where they randomly show posts to users. The second baseline uses the level of interaction between the user and their friend and predicts &lt;em&gt;limit sharing&lt;/em&gt; for friends with low levels of interaction.&lt;/p&gt;

&lt;p&gt;For their experiments, they used two datasets. One called the &lt;strong&gt;post dataset&lt;/strong&gt; containing 389 posts and another called the &lt;strong&gt;friend-post dataset&lt;/strong&gt; containing 2336 labels. Each dataset has different goals. In the &lt;strong&gt;post dataset&lt;/strong&gt;, they try to predict whether a user should decrease the audience of a post. In this &lt;strong&gt;friend-post dataset&lt;/strong&gt;, they try to predict whether or not a specific friend’s access to the post should be removed. The difference in the datasets is that the &lt;strong&gt;friend-post dataset&lt;/strong&gt; contains six times as much data (and therefore labels) because it has the decisions made for the six friends that were randomly shown.&lt;/p&gt;

&lt;p&gt;The metrics that they used for evaluation were the precision and for &lt;em&gt;limit sharing&lt;/em&gt;. In addition, they also include &lt;a href=&quot;https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_K&quot;&gt;precision at K&lt;/a&gt; which is the precision after predicting the top K results as positive. They included precision at K because they could vary the number of posts shown to a user.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;
&lt;p&gt;On the &lt;strong&gt;friend-post dataset&lt;/strong&gt;, they found that the XGBoost model had the highest precision at K performing the best for even low values of K. In examining the precision-recall curve, they found that when K was set to 30  they found that the precision-recall area under the curve (PR AUC) was 0.493 which was much higher than the 0.118 PR AUC achieved by the interaction baseline model. The reason 30 was used as the value of K was that it corresponds with the underlying distribution of &lt;em&gt;limit sharing&lt;/em&gt;. Mandal et al. also tried to find the most predictive features. In the table below, you’ll see the top 10 features for the XGBoost model.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/set-it-and-forget-it/table4.png&quot; alt=&quot;table 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For both datasets, they analyzed which posts their classifier was wrong. One of their findings was that a significant number of misclassified posts were those that linked to external content like images or videos. Mandal et al. didn’t collect features specific to a posts’ external content for privacy reasons and because it wasn’t supported by current literature. They also found that another source of inaccuracy for misclassified posts (16%) was that they didn’t have features specific to participant’s friends. An example provided in the paper pertaining to why a participant would share a post with a particular friend was “I think she likes articles about animals.”&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;In this work, Mandal et al. find that for Facebook users access control is usually set-it and forget-it but that has longer term implications as a user’s life changes, the number of posts they have increase, and the number of friends they have rises. Moreover, predicting whether or not to limit sharing of a post with a particular through the use of machine learning models is more effective than simply relying on the interaction between users.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;[1] Statista. 2018. Number of Facebook users by age in the U.S. as of January 2018
(in millions). https://www.statista.com/statistics/398136/us-facebook-user-agegroups/. (Last accessed in August 2019).&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">Moving Beyond Set-It-And-Forget-It Privacy Settings on Social Media Mainack Mondel et al., Conference on Computers and Communication Security 2019</summary></entry><entry><title type="html">A Usability Evaluation of Let’s Encrypt and Certbot: Usable Security Done Right</title><link href="http://localhost:4000/paper%20summary/certbot/" rel="alternate" type="text/html" title="A Usability Evaluation of Let’s Encrypt and Certbot: Usable Security Done Right" /><published>2020-02-01T00:00:00-08:00</published><updated>2020-02-01T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/certbot</id><content type="html" xml:base="http://localhost:4000/paper%20summary/certbot/">&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3319535.3363220&quot;&gt;“A Usability Evaluation of Let’s Encrypt and Certbot: Usable Security Done Right”&lt;/a&gt; Tiefenau et al., &lt;em&gt;Conference on Computers and Communication Security 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When looking through the CCS proceedings, I knew that I had to find out more about the work by Tiefenau et al., purely by the title alone. What stuck out about the title in particular was the “Usable Security Done Right” subtitle. There’s been a trend in the Usable Security space of extracting a provocative quote from a survey or study participant that shows their misunderstanding of a method, technology, protocol, etc. and using that as part of the title. This paper didn’t didn’t do that but rather highlighted a certain tool that was getting things right. While my curiosity was piqued by the title, the rest of the paper definitely didn’t disappoint.&lt;/p&gt;

&lt;h2 id=&quot;tls-tls-tls&quot;&gt;TLS TLS TLS&lt;/h2&gt;

&lt;p&gt;Transport Layer Security (TLS) is one of the protocols that people interact with pretty much every day without thinking about it. With its importance to securing data and how frequently people interact with it, it has been a subject of a lot of usable security research. Most of that research has focused on how users perceive TLS warnings and how to potentially improve them. While understanding the user side of things is important, it leaves out the other essential and less-studied side: server configuration. That’s where &lt;a href=&quot;https://letsencrypt.org/&quot;&gt;Let’s Encrypt&lt;/a&gt; and &lt;a href=&quot;https://certbot.eff.org/&quot;&gt;Certbot&lt;/a&gt; come in. Certbot helps automates the acquisition of certificates from Let’s Encryption and the parts of the configuration on web servers.&lt;/p&gt;

&lt;h2 id=&quot;what-were-they-looking-for&quot;&gt;What were they looking for?&lt;/h2&gt;

&lt;p&gt;In their work, Tiefenau and his colleagues tried to find out the advantages of using Let’s encrypt through a randomized controlled trial comparing Let’s Encrypt and Certbot to a traditional CA. More specifically they had the following research questions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Does Certbot support its users in fulfilling the task of en-abling TLS?&lt;/li&gt;
  &lt;li&gt;How do participants perceive Certbot’s functionality and usability?&lt;/li&gt;
  &lt;li&gt;How can the Certbot process be improved?&lt;/li&gt;
  &lt;li&gt;How does task framing affect how participants behave in the study?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lets-talk-design&quot;&gt;Let’s talk design&lt;/h2&gt;

&lt;h3 id=&quot;overall-design&quot;&gt;Overall Design&lt;/h3&gt;
&lt;p&gt;The study design that Tiefenau et al. used was based on a study conducted by Krombholz et al [1]. There were two differences between the designs of the two studies 1) in Tiefenau et al.’s study they had two treatment groups which were a conventional CA and Certbot + Let’s Encrypt CA and 2) they also examined the skill of the participants by making them also perform server related actions such as proving server ownership. Another element that they added to to the study was the concept of framing. As mentioned earlier, they tried to understand if framing had an effect on how participants performed. They tried to accomplish this by creating a role-playing scenario for half of the participants were they were to imagine that they were working for a company. They made this scenario more realistic by using tailoring the URLs, usernames and passwords. When first reading the paper, I was a bit confused about which part of the study was within-subjects and which part was between-subjects but the table below really clears things up.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/certbot/table1.png&quot; alt=&quot;table1 1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tasks&quot;&gt;Tasks&lt;/h3&gt;
&lt;p&gt;Each participant had to complete four tasks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Task 1: The user had to SSH into the server and move web pages to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;www&lt;/code&gt; directory. This task was used to get a baseline of the participant’s Linux skill level.&lt;/li&gt;
  &lt;li&gt;Task 2: The participant had to acquire the certificate from a traditional CA or they have to use certbot to acquire a cert and install it on the server&lt;/li&gt;
  &lt;li&gt;Task 3: The participants in the traditional CA treatment had to install the certificate&lt;/li&gt;
  &lt;li&gt;Task 4: Participants checked their server configuration using Qualys SSL Server Test&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Participants had to complete each of the four tasks for both treatments and were given a time limit of 2 hours for the Certbot task and 3 hours for the traditional CA task. After the completion of each task they completed a questionnaire that asked them to assess their performance and contained questions about the tasks themselves. At the conclusion of both tasks they completed a final questionnaire which compared the two options.&lt;/p&gt;

&lt;h3 id=&quot;participants-and-support-channel&quot;&gt;Participants and Support Channel&lt;/h3&gt;
&lt;p&gt;To substitute for an expert population, Tiefenau et al.used a class of computer science students. As would be expected the demographics of the group skewed male and young. About 71% of the participants had experience as a sysadmin but over half had never configured TLS before.&lt;/p&gt;

&lt;p&gt;The last and the most interesting part of the study design to me was the support channel that they set up. They used this channel two counter two common issues in user studies with complex tasks: 1) participants failing early and never getting to the task of interest and 2) participants forgetting the issues they ran into when trying to complete a long procedure. In terms of participants failing early, they were able to give appropriate hints or nudges in the case a participant was having trouble SSH’ing into the server. Also, they were able to get immediate feedback when a participant ran into a problem because they would send them a message. Tiefenau et al. used a playbook to decide what help to provide to participants and what type of delay to use in responding.&lt;/p&gt;

&lt;h2 id=&quot;configure-or-not-there-is-no-try&quot;&gt;Configure or not, there is no try&lt;/h2&gt;
&lt;p&gt;Now, that we’ve detailed the study design, let’s talk about how the participants did.&lt;/p&gt;

&lt;p&gt;The completion results between the traditional CA treatment and the Certbot treatment were pretty eye-opening. 28 (90%) of participants were able to deploy a certificate from Let’s Encrypt using certbot as compared to only 16 (52%) with the traditional approach. It’s pretty clear that certbot drastically improved participants ability to configure TLS on a web server. The table below shows the different points that participants failed at.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/certbot/table3.png&quot; alt=&quot;table 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The results regarding the time to configure TLS followed the same trend as the completions results. The median time for Certbot task was 18 minutes compared to the 65 minutes for the traditional CA task.&lt;/p&gt;

&lt;p&gt;A finding that the authors found surprising was that participants performed well with security and CA parts; however, they struggled with the tasks that were specific to configuring Apache which was used as the webserver. These problems ranged from being able to perform the ownership verification to not knowing enable the SSL module of Apache2.&lt;/p&gt;

&lt;p&gt;In the comparison survey, the combination of Let’s Encrypt and Certbot won out in every category except transparency. The reason for this was most likely because of the automation that Certbot provides potentially masking steps in the process.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/certbot/figure2.png&quot; alt=&quot;figure 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In terms of framing, they didn’t not find any difference in the behavior of participants.&lt;/p&gt;

&lt;h2 id=&quot;tell-me-whats-good-or-bad&quot;&gt;Tell me what’s good (or bad)&lt;/h2&gt;

&lt;h3 id=&quot;the-bad&quot;&gt;The bad&lt;/h3&gt;
&lt;p&gt;One of the negative things called out in the post-task questionnaire and the comparison survey was that actions taken by Certbot weren’t transparent to the user. One participant in particular had the following remark:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;everything was easy,but […] Certbot is not transparent to me. I do not know what it ac-tually did and the whole process inside, for me it is like (a) blackbox”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The authors point out that Certbot has a verbose option but none of the participants chose to use it. Nevertheless, it seems like the default verbosity should be increased.&lt;/p&gt;

&lt;p&gt;The next thing that users commented on was that Certbot didn’t offer more advanced security configurations. The authors counterpoint to this was that Certbot has to be general to support different use cases and administrators and it is on the right path; however, they do suggest that future work should look into the tradeoff between security and generalizability.&lt;/p&gt;

&lt;h3 id=&quot;the-good&quot;&gt;The good&lt;/h3&gt;

&lt;p&gt;The authors pointed out that the simplicity of the Certbot is one of the key factors of it success and most importantly it didn’t require to have knowledge about the process.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Certbot applied the knowledge of its experts auto-matically with little need for specialized knowledge, by guiding the user through the process using a dialog-like approach instead of requiring multiple commands on the command line.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The other part of it’s usability as stated by the authors was that it used safe defaults and automated several steps while only introducing two new ones.&lt;/p&gt;

&lt;h2 id=&quot;wrap-up&quot;&gt;Wrap Up&lt;/h2&gt;

&lt;p&gt;The combination of Let’s Encrypt and Certbot show that when “administrator-centered engineering” is combined with simplicity problems that are long considered hard to solve at scale can be become significantly easier&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Katharina Krombholz, Wilfried Mayer, Martin Schmiedecker, and Edgar R. Weippl.”I Have No Idea What I’m Doing” - On the Usability of Deploying HTTPS. In 26th USENIX Security Symposium, USENIX Security 2017, 2017.&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">“A Usability Evaluation of Let’s Encrypt and Certbot: Usable Security Done Right” Tiefenau et al., Conference on Computers and Communication Security 2019</summary></entry><entry><title type="html">“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers</title><link href="http://localhost:4000/paper%20summary/usability-smartphone-pm/" rel="alternate" type="text/html" title="“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers" /><published>2020-01-25T00:00:00-08:00</published><updated>2020-01-25T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/usability-smartphone-pm</id><content type="html" xml:base="http://localhost:4000/paper%20summary/usability-smartphone-pm/">&lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/10.1145/3319535.3354192&quot;&gt;“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers&lt;/a&gt; Seiler-Hwang et al., &lt;em&gt;Conference on Computers and Communication Security 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Moving on from SOUPS, I took a look at the &lt;a href=&quot;https://sigsac.org/ccs/CCS2019/index.php/proceedings/&quot;&gt;proceedings&lt;/a&gt; from the Conference on Computers and Communication Security (CCS) and the first paper to catch my eye was the work by Seiler-Wang et al. The thing that stuck out about their work was that they studied a particular security tool that was popularized on desktops, in this case password managers (PM), and sought to understand the usability issues when used on a mobile device.&lt;/p&gt;

&lt;h2 id=&quot;setting-the-stage&quot;&gt;Setting the stage&lt;/h2&gt;
&lt;p&gt;For those who aren’t familiar with password managers, they’re digital wallets or vaults that assist in storing passwords or other secrets associated with different sites and services. In addition, to simply storing passwords they can help with password generation. While they can be immensely helpful, their usage is not widespread. According to two studies cited in the paper, password manager usage was seen to be at 17.6% [1] in 2016 and 16.7% [2] in 2018. However, mobile password usage is only at 6.8% [1]. The hypothesis is that usability issues are a factor and the authors seek to find out what those issues are.&lt;/p&gt;

&lt;h2 id=&quot;so-what-did-they-do&quot;&gt;So what did they do?&lt;/h2&gt;
&lt;p&gt;The authors conducted a usability study of four popular password managers: Dashlane, LastPass, Keeper and 1 Password. Each participant had to complete seven tasks ranging from installing and registering on the PM app to adjusting the security configurations of the PM.&lt;/p&gt;

&lt;p&gt;They evaluated their study using two tools: the standard System Usability Scale (SUS) and PACMAD (People at the Center of Mobile Application Development). Before reading this paper, I didn’t know that certain SUS scores were used to describe the general usability such as SUS scores with at least 70 means the product is &lt;em&gt;acceptable&lt;/em&gt;. You can see the other mappings in the figure below. PACMAD is an evaluation framework specific for mobile devices that focuses on seven attributes: effectiveness, efficiency, learnability, memorability, errors and cognitive load. They were able to evaluate these different attributes though the SUS, NASA Task Load Index, and a set of questionnaires.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/mobile-password-managers/figure1.png&quot; alt=&quot;figure 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;They recruited participants through MTurk and had 20 participants complete the seven tasks for each of the four PMs resulting in 80 sets of responses. The user population that took part in the study was predominantly male, well educated, skewed young, and were mostly Android users. So the authors say that their results might not generalize well.&lt;/p&gt;

&lt;h2 id=&quot;certain-password-managers-are-better-than-others&quot;&gt;Certain password Managers are better than others&lt;/h2&gt;
&lt;p&gt;When looking at both the PACMAD Attributes and the SUS scores for each of the PMs, there were some interesting results. Let’s first start by looking at some of the PACMAD attributes.&lt;/p&gt;

&lt;h3 id=&quot;pacmad&quot;&gt;PACMAD&lt;/h3&gt;
&lt;p&gt;When evaluating the effectiveness of the four PMs, they all had a 90% success rate on average when combining the results from each of the tasks which is considered good. However, the task that had the lowest success rate was one which required the participant to download a native app for a service and login using a password stored in the PM. Participants were confused about the need to enable certain system-level permissions in order to enable auto-fill functionality. The authors hypothesize that this confusion is a result of a knowledge gap between certain groups of users.&lt;/p&gt;

&lt;p&gt;In contrast to effectiveness where each PM performed similarly, there were statistical differences found in the learnability of the different PMs.  Dashlane proved to have the highest learnability value (M = 75.6) with 1Password having the lowest score (51.3). The authors found that the learnability of Dashlane, LastPass and Keeper is similar with each being deemed “acceptable” according to the SUS. 1Password’s lower score was statistically different and fell in the “not acceptable” category according to the SUS.&lt;/p&gt;

&lt;h3 id=&quot;sus-scores&quot;&gt;SUS Scores&lt;/h3&gt;
&lt;p&gt;Dashlane received the highest average SUS score with a 76.5 while 1Password was the lowest receiving a 52.6. Based on the descriptions described earlier only Dashlane and Keeper have SUS scores that are deemed “acceptable”. Lastpass would be considered “marginal high” and 1Password would be in the “low marginal category.”  The figure below shows the distributions of the responses to the likert items that compose the SUS questionnaire.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/mobile-password-managers/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The authors also tried to understand the influence of demographics on the usability scores for each PM by using multiple linear regression and found that each model was not statistically significant.&lt;/p&gt;

&lt;h2 id=&quot;author-recommendations&quot;&gt;Author Recommendations&lt;/h2&gt;
&lt;p&gt;The authors’ recommendations to improve password managers to improve adoption centered around three things: User Guidance and Interaction, Integration and Security.&lt;/p&gt;

&lt;p&gt;On the &lt;strong&gt;user guidance front&lt;/strong&gt;, they detail how the PMs need to do three things:&lt;/p&gt;

&lt;p&gt;1) educate users on what PMs are, how they help with security, and the role of master passwords&lt;/p&gt;

&lt;p&gt;2) provide instructions on how to use basic functionalities&lt;/p&gt;

&lt;p&gt;3) better explain the different security settings&lt;/p&gt;

&lt;p&gt;The authors mention that this could be done with better help menus, tutorials, and instructions.&lt;/p&gt;

&lt;p&gt;In terms of &lt;strong&gt;integration&lt;/strong&gt;, the authors call out how their study found that not only was auto-fill the most useful feature, but also the most problematic. They recommend that mobile OSs offer better integration APIs and that native apps be more PM friendly.&lt;/p&gt;

&lt;p&gt;When it came to &lt;strong&gt;security&lt;/strong&gt;, the authors start by saying that better security leads to more user trust which can foster adoption. Specifically, they speak to the different policies surrounding the master password for each of the PMs with some accepting weaker password. They recommended having strong password policies for the master password and to provide feedback for users through password strength meeters and to offer additional levels of protection like MFA. Last, they talk about the trade-offs users make when adjusting security settings. They recommend that PMs provide additional feedback so that users are made aware of how the changes they’re making impact their security.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;I thought that work by Seiler-Hwange et. al, was particularly insightful and showed that there is still a lot of work that needs to be done to improve the usability of mobile password managers.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;.. a comparison of three biometrics (voice, face and gesture) against traditional passwords, concluded that the latter were the most usable with a SUS of 78, still a higher score than that of current popular PMs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My hope is that the entities developing them take this feedback and use it to develop more usable products because by doing so they will help reduce password re-use and improve the security of others.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;p&gt;[1]Nora Alkaldi and Karen Renaud. 2016. Why Do People Adopt, or Reject, Smart-phone Password Managers?. In 1st European Workshop on Usable Security (EuroSec2016). 1–14&lt;/p&gt;

&lt;p&gt;[2]Elizabeth Stobert and Robert Biddle. 2018. The password life cycle. ACM Transactions on Privacy and Security (TOPS) 21, 3 (2018), 13&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">“I don’t see why I would ever want to use it”: Analyzing the Usability of Popular Smartphone Password Managers Seiler-Hwang et al., Conference on Computers and Communication Security 2019</summary></entry><entry><title type="html">Keepers of the Machines: Examining How System Administrators Manage Software Updates For Multiple Machines</title><link href="http://localhost:4000/paper%20summary/keepers/" rel="alternate" type="text/html" title="Keepers of the Machines: Examining How System Administrators Manage Software Updates For Multiple Machines" /><published>2020-01-17T00:00:00-08:00</published><updated>2020-01-17T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/keepers</id><content type="html" xml:base="http://localhost:4000/paper%20summary/keepers/">&lt;p&gt;&lt;a href=&quot;https://www.usenix.org/system/files/soups2019-li.pdf&quot;&gt;Keepers of the Machines: Examining How System
Administrators Manage Software Updates&lt;/a&gt; Li et al., &lt;em&gt;SOUPS 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Continuing through the SOUPS proceedings, I wanted to take some time to write about this paper by Frank Li, et. al. Their work focusing on the perspective of the administrator as it relates to managing software updates received the Distinguished Paper Award. I think what stood out about this paper is their focus on the admin. Most of the literature surrounding updating focuses on the end-user which is useful; however, admin who manages thousands of devices has to consider different things. In their work, they do an in-depth investigation of the process admins follow when updating the machines they manage.&lt;/p&gt;

&lt;h2 id=&quot;tell-me-about-the-data&quot;&gt;Tell me about the data&lt;/h2&gt;

&lt;p&gt;The data that they collected as part of this study came from two sources: a survey and semi-structured interviews. The survey that they administered had 41 questions and the participants were recruited through social media, blogs, and at the Large Installation System Administration Conference (LISA) conference. In total, they had 102 people take the survey. They coded the open-ended questions from the survey using open coding by two researchers. For the semi-structured interviews, they had 17 interview subjects which took part in interviews that ranged from 1 - 3 hours. Similar to the open-ended questions, two of the researchers coded the interview responses.&lt;/p&gt;

&lt;p&gt;The population that they interviewed was mostly male with 6/102 survey and 2/17 interview subjects being female. The survey respondents on average had a median of 11 years of experience, while the median for the interview subjects was 6 years. Another piece of demographic information that I found interesting was that almost half of the participants for both the survey (56/102) and the structured interviews (8/17) worked at organizations with more than 500 employees.&lt;/p&gt;

&lt;p&gt;After reading some of those demographic details, you are probably thinking that the respondents might not be representative of system admins in general and the authors would agree with you. In their paper, they call out that because of where and how they recruited participants their findings may not be representative of all admins.&lt;/p&gt;

&lt;h2 id=&quot;five-stages-of-updating&quot;&gt;Five Stages of Updating&lt;/h2&gt;

&lt;p&gt;From the data collected through the survey and the structured interviews, they found that the update process for administrators followed five stages:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Learning about updates from information sources&lt;/li&gt;
  &lt;li&gt;Deciding to update based on update characteristics&lt;/li&gt;
  &lt;li&gt;Preparing for update installation&lt;/li&gt;
  &lt;li&gt;Deploying the update&lt;/li&gt;
  &lt;li&gt;Handling post-deployment updates issues.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;where-do-you-get-your-info&quot;&gt;Where do you get your info&lt;/h3&gt;
&lt;p&gt;In both the survey and the interviews, they asked participants where they found out about updates. The participants provided a range of different sources which can be seen in Table 1 below.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/keeper/table1.png&quot; alt=&quot;table 2&quot; height=&quot;274px&quot; width=&quot;385px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The median survey respondent reported using a median of 5.0 different types of sources. The authors confirm what I thought while reading this paper – that admins could miss out on relevant information if they don’t follow a source in general or don’t diligently follow their usual sources. In addition, several of the sources named like blog posts and social media require the admin to take some action in order to receive any information.&lt;/p&gt;

&lt;h3 id=&quot;decisions-decisions&quot;&gt;Decisions, Decisions&lt;/h3&gt;

&lt;p&gt;After administrators find out about updates, they have to decide if they are going to actually deploy them. From the survey and interviews they found five general factors that affect whether or not they are going to apply an update:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update type&lt;/strong&gt;: The authors aksed the survey admins how regularly they installed security or non-security updates. They found that 97/102 admins regularly installed security updates while only 63/102 regularly installed non-security updates. The sentiment of regularly installing security updates was shared by the interview participants. The authors noted that while admins prioritize fixing security bugs/vulns many platforms bundle security patches along with along with other features. This means that they have to consider more than just improved security when applying updates.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update Severity&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update Relevance&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Update Reliability&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Organization Factors&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;proper-preparation-prevents-poor-performance&quot;&gt;Proper Preparation Prevents Poor Performance&lt;/h3&gt;

&lt;p&gt;Once admins have decided to roll out an update, they made preparations that fell in three categories: making backups/snapshots, preparing machines in terms of changing configurations or dependencies and testing updates for bugs.&lt;/p&gt;

&lt;p&gt;In both the survey and semi-structured interviews, the authors asked participants about the problems that they’ve run into when trying to apply updates. The general sentiment was that it wasn’t an entirely easy process and that there was some risk even if it was small. The responses showed that some admins had worse experiences than others.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I stopped applying updates because it was becoming more
of a problem to apply them than not to. Production machines, they
don’t get updates” (P12).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think it’s important to note that P12 probably has the best of intentions and desires when it comes to maintaining their organizations infrastructure, but they are jaded from their experience.&lt;/p&gt;

&lt;p&gt;When asked about the testing strategies that admins used for updates, most fell into one or two camps: staggered deployments or dedicated testing environments. Those that utilized staggered deployment had a few different approaches. One approach was applying updates based on priority levels with lower priority machines getting the updates first to uncover any potential issues. Another approach was to have a group of end users to help with update testing. For those that fell into the the dedicated testing, they used dedicated hardware or relied on a quality assurance (QA) team to to test updates.&lt;/p&gt;

&lt;p&gt;The authors note that both of these strategies have their downsides. When using the staggered deployment approach, higher priority machines or certain groups of users are left more susceptible to potential attackers. And to perform dedicated testing, admins must have access to the computing resources or employees which are dedicated to testing.&lt;/p&gt;

&lt;h3 id=&quot;ship-it&quot;&gt;Ship It&lt;/h3&gt;
&lt;p&gt;When asked how they deployed updates, the authors received a variety of answers from in-house scripts, automatic updates, to manual application. In addition, the methods that they used was dependent on the machine being updated. The majority of respondents used some type of third-party update manager such as Ansible or Chef to apply updates and   about half created custom scripts to deploy updates. While the respondents detailed the importance of automation when managing hundreds of machines, they also noted the effort that it takes to get that automation right.  Also, to no one’s surprise, manual updates were still common with 40/102 survey respondents and 4/17 interview subjects saying they conducted manual updates.&lt;/p&gt;

&lt;p&gt;The “when” to deploy is probably just as important as the how. Most of the interview subjects when asked when they would apply updates used either a predictable schedule such as a weekly patching program or to update during off-hours.&lt;/p&gt;

&lt;h3 id=&quot;it-worked-on-my-machine&quot;&gt;It worked on my machine.&lt;/h3&gt;
&lt;p&gt;As noted before applying updates can sometimes come with issues. The two most common approaches were to either just uninstall the update or rollback to a previous snapshot or backup. Both of these strategies aren’t great in that they leave the machines in their previous state which means that they’re potentially vulnerable if the update involved security patches. The two approaches really enforce the mindset that admins really want people to be able to get their jobs done. They are prioritizing functionality over security.&lt;/p&gt;

&lt;h2 id=&quot;lets-ask-the-boss&quot;&gt;Let’s ask the boss&lt;/h2&gt;

&lt;p&gt;The admins in this study had different organization policies or oversight when it came to applying updates. Some were given the autonomy to apply updates as they saw fit, some had to get buy-in from management before they could perform certain actions, and others had to comply with organizational policies or compliance requirements. Another unfortunate but not surprising finding by the authors was that several of the admins in this study commented on the not having budget to support admin operations surrounding updating such as software to deploy updates.&lt;/p&gt;

&lt;h2 id=&quot;so-what-should-change&quot;&gt;So what should change?&lt;/h2&gt;
&lt;p&gt;In the paper, the authors make several suggestions to ease the pain of managing software updates.&lt;/p&gt;

&lt;p&gt;When it came to finding out about updates, they suggest standardization and the consolidation update information into one place so that there’s a single source of truth. They also mention the possibility of outreach campaigns to promote updating and inform admins of vulnerabilities.&lt;/p&gt;

&lt;p&gt;To ease the decision making process of whether or not to install an update, the authors suggest splitting all-inclusive updates into updates of specific types. I think this is an interesting approach but one that could cause potentially more problems than good especially for platforms or software that is used by enterprises and common users. I personally would like to see some data surrounding the potential consistency in which users would install security only patches.&lt;/p&gt;

&lt;p&gt;To improve the deployment process, the authors encourage the usable security community to take a look a the common update tools to see how their interfaces could be improved. They also mentioned that dynamic software updating (DSU) which help the dreaded restart or downtime could help alleviate some of the problems associated with finding the right time to deploy. The authors relent that there are still a lot of unknowns surrounding the increased difficulty in developing patches that use DSU and the general usability of those systems.&lt;/p&gt;

&lt;p&gt;Last, the authors speak to the need for a cultural shift at organizations to understand the importance of quickly applying updates, especially those of the security variety. Moreover, they mention that without proper resources surrounding applying patches that security lapses like data breaches can occur. While they point out the importance of having organization support when it comes to applying patches, they note that getting to an ideal state is not straightforward.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;Frank Li and his co-authors point out that&lt;/p&gt;

&lt;p&gt;1) There are some similarities between the update process for admins and end-users but that admins have different considerations and operate on different scales&lt;/p&gt;

&lt;p&gt;2) There are distinct pain points throughout the admin’s process and there needs to be further research surrounding solutions to these pain points.&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">Keepers of the Machines: Examining How System Administrators Manage Software Updates Li et al., SOUPS 2019</summary></entry><entry><title type="html">Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries</title><link href="http://localhost:4000/paper%20summary/usability-smells/" rel="alternate" type="text/html" title="Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries" /><published>2020-01-09T00:00:00-08:00</published><updated>2020-01-09T00:00:00-08:00</updated><id>http://localhost:4000/paper%20summary/usability-smells</id><content type="html" xml:base="http://localhost:4000/paper%20summary/usability-smells/">&lt;p&gt;&lt;a href=&quot;https://www.usenix.org/system/files/soups2019-patnaik.pdf&quot;&gt;Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries&lt;/a&gt; Patnaik et al., &lt;em&gt;SOUPS 2019&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;While at SOUPS, this particular paper stood out because it related to some work that my colleagues and I were doing surrounding certificate chain validation. Cryptography is hard and using cryptographic APIs can be difficult too. This work uncovers usability smells associated with popular cryptography libraries by conducting a thematic analysis of 2,491 StackOverflow questions. A &lt;em&gt;usability&lt;/em&gt; smell is some sort of hint or indication that an interface may be difficult to use for its intended users. Usability smells are often thought of as it relates to graphical user interfaces (GUIs), but this way of thinking can be applied to APIs too.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Developers struggle with programming interfaces in the same way that users struggle with user interfaces.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;we-all-use-stack-overflow-right&quot;&gt;We all use Stack Overflow, right?&lt;/h2&gt;

&lt;p&gt;The researchers looked into seven popular cryptography libraries which are listed in the table below:&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table1.png&quot; alt=&quot;table 1&quot; height=&quot;660px&quot; width=&quot;344px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using the library names of the seven libraries as search terms, the researchers scraped Stack Overflow and found 2,491 questions. They did some post processing of the original corpus of questions to remove questions that didn’t relate to an issue in the library itself or where a developer wrongly attributed a question to a particular library. After this filtering, they were left with 2,316 questions to perform thematic analysis on.&lt;/p&gt;

&lt;p&gt;The researchers acknowledged that there were a couple of threats to the validity of their work: namely the staleness of questions and that the problem posed in the question was only encountered by a single developer and thus wasn’t a general problem with the library. To mitigate the first threat, they validated that the usability issued they identified was still present in the current version of the library. And to mitigate the seecond threat, they only selected questions that had a score of at least 1.&lt;/p&gt;

&lt;h2 id=&quot;the-issues&quot;&gt;The Issues&lt;/h2&gt;

&lt;p&gt;Through thematic analysis, the researchers found 16 usability issues that they grouped into 7 themes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/usability-smells/figure3.png&quot; alt=&quot;figure 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Most of the issues are pretty intuitive and what you might be used to seeing on Stack Overflow. One of the issues that stood out to me was &lt;em&gt;borrowed mental models&lt;/em&gt; because I was wondering what it meant in this context. This particular issue arises when a develper tries to apply concepts from one library to another.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table2.png&quot; alt=&quot;table 2&quot; height=&quot;274px&quot; width=&quot;385px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The lionshare of the issues they found were with OpenSSL and  the two most prevalent types of issues were “What’s gone wrong here” (259) and “Build Issue” (362). This means that developers were having a lot of diffculty just setting up OpenSSL let alone actually using it.&lt;/p&gt;

&lt;p&gt;In contrast, LibSodium had the least amount of issues with a total of 26 relevant issues. Maybe that is to be expected from library whose claims to be a “modern, portable, easy to use crypto library.”&lt;/p&gt;

&lt;h2 id=&quot;usability-smells&quot;&gt;Usability Smells&lt;/h2&gt;
&lt;p&gt;After identifiying the themes associated with the issues in the Stack Overflow questions, the researchers attempted to map them onto the 10 usability principles  by Green and Smith. They did not map the &lt;em&gt;lack of knowledge&lt;/em&gt; or &lt;em&gt;passing the buck&lt;/em&gt; issues since these are associated with specific developer behaviors and aren’t associated with the problems with the library itself. Through the mapping they found four usability smells which can be found in the table below:&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table3.png&quot; alt=&quot;table 3&quot; height=&quot;918px&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Needs a super sleuth&lt;/strong&gt;: this smell means usually means it is hard to find the information you need to accomplish a particular task or that it is diffcult to understand how to do it with the library.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Confusion regins&lt;/strong&gt;: this usability smells comes out before any code is written. The developer is unsusre if this is right library to use or how to use the library.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Needs a post-mortem&lt;/strong&gt;: unlike &lt;em&gt;confusions regins&lt;/em&gt; the issues associated with this smells happen after writing code. Whether it is because an update has broken their code or they are generally struggling to use the library, something went wrong.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Doesn’t play well with others&lt;/strong&gt;. For a library to be easy-to-use, a developer must be able to actually use it.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-bad-are-the-smells&quot;&gt;How bad are the smells?&lt;/h2&gt;

&lt;p&gt;For the three libraries that that had the most issues OpenSSL, Bouncy Castle, and PyCrypto, the researchers added what they call a &lt;em&gt;Whiffiness factor&lt;/em&gt;. It is a weighted average of the percentage frequency of the issues associated with each whiff.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img src=&quot;/assets/images/usability-smells/table4.png&quot; alt=&quot;table 3&quot; height=&quot;812px&quot; width=&quot;564px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Of the three libraries analyzed, OpenSSL came out to be the “stinkiest” but in reality it’s not much different than the other libraries. There are areas that it shines and areas that need some improvement.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up&quot;&gt;Wrapping Up&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Libraries will perhaps always be a bit smelly given
the challenges of catering for the requirements of a wide and
diverse set of developers and applications; but by integrating
usability principles we can at least make them less so.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Olabode Anise</name></author><category term="paper summary" /><category term="security" /><summary type="html">Usability Smells: An Analysis of Developers’ Struggle With Crypto Libraries Patnaik et al., SOUPS 2019</summary></entry><entry><title type="html">Recommitment to Usable Security</title><link href="http://localhost:4000/general/recommitment/" rel="alternate" type="text/html" title="Recommitment to Usable Security" /><published>2020-01-06T00:00:00-08:00</published><updated>2020-01-06T00:00:00-08:00</updated><id>http://localhost:4000/general/recommitment</id><content type="html" xml:base="http://localhost:4000/general/recommitment/">&lt;p&gt;We’re a few days into 2020, and like a lot of people I’ve tried to set my intentions/goals for the year. One of those intentions is to recommit myself to studying and learning about the field of Usable Security.&lt;/p&gt;

&lt;p&gt;In a past life, I was a PhD student at the University of Florida studying Usable Security as part of the Human-Centered Computing Program. For a few reasons that I won’t get into, I left the program after my first year to work at Duo Security. Looking back, I’m so glad that I made that decision. It has afforded me the opportunity to work with great people and to work on some really cool projects. Unfortunately, most of my work as a Data Scientist doesn’t afford me the opportunity to work in the Usable Security space. To pile on, my pursuit of a master’s degree didn’t allow me to really scratch that itch or really do much of anything outside of work. But with that degree completed and with a bit of free time back, I want to invest that time in learning and growing in an area I’m passionate about.&lt;/p&gt;

&lt;p&gt;So my goal for 2020 is to read more usable security papers and to write some paper summaries as way of solidifying my understanding of what I read as well as improve my technical writing. I’m hoping to write at least one paper summary a week in the style of &lt;a href=&quot;https://blog.acolyer.org/&quot;&gt;the morning paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I like to look for tools to hold myself accountable and now that I’ve written this post and put it on the Internet I guess I’ve found one for this goal :).&lt;/p&gt;</content><author><name>Olabode Anise</name></author><category term="general" /><summary type="html">We’re a few days into 2020, and like a lot of people I’ve tried to set my intentions/goals for the year. One of those intentions is to recommit myself to studying and learning about the field of Usable Security.</summary></entry></feed>